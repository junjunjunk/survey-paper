---
layout: post
title:  "Mesh-TensorFlow: Deep Learning for Supercomputers"
date:   2019-07-08
categories: parallelization deeplearning
---

## 1. どんなもの？
学習の並列化に特化した深層学習フレームワーク。データ並列・モデル並列を両方カバーしている。特にモデル並列部分に注力したフレームワークらしい。主にTransformerというモデルをターゲットにしている。集合通信等が実装されている。

"Mesh"という言葉はネットワークで繋がっているN次元配列のプロセッサと定義されている。ちなみにスーパーコンピュータの構造はプロセッサがN次元配列的に配置され、それぞれのプロセッサが隣り合ったプロセッサと接続されている、という構成が多いイメージだ。このMeshの全てのプロセッサに対して、テンソルを分割（もしくは複製）することを考える。どのようにテンソルを分割してプロセッサに配置するかをLayoutと呼んでいる。Layoutはパフォーマンスにのみ影響があり結果は変わらない。（ただし丸め誤差とランダムシードには影響がある。）また、それぞれのテンソルに次元を定義してあげることでテンソル自身の分割もサポートしている。

例としては例えば画像のバッチテンソルがあったとすると、テンソルの次元は以下のように分割できる。（左要素はテンソルの次元名、右はその次元での値を表す。）

[("batch", 100), ("rows", 28"), ("cols", 28), ("channels", 3)].

どのように分割を行えるのかはgithubのREADMEのLayouts
が非常に参考になる。説明は省略するが分割の例の図だけ掲載する。

![Figure 1](./img/Mesh-TensorFlow_Deep_Learning_for_Supercomputers/img/fig1.png)

![Figure 2](./img/Mesh-TensorFlow_Deep_Learning_for_Supercomputers/img/fig2.png)


計算の際のピークメモリ消費量を最小にするようにLayoutを決定するような機能も現在ある。これは混合整数線形計画法を解くアルゴリズムで動作する。

実験はTPUで行われているがCPUやGPUでも動くと記述はされている。
- [Auto MTF](https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/auto_mtf/README.md)

## 2. 先行研究と比べてどこがすごいの？
今まで通常のtensorflowのみではデータ並列は実装できてもモデル並列については実装できなかった。なぜならば現在の主流な並列化はデータ並列だからだ。そのため分散学習を行う時に、メモリ容量の都合でデータ並列が適用できないモデル等に関しては、tensorflowを用いることができなかった。それに対してmesh-tensorflowはモデル並列に対応したフレームワークである。


## 3. 技術や手法の"キモ"はどこにある？
モデル並列を記述できるフレームワークであるという点が重要。今まではデータ並列にのみ対応しているフレームワークがほとんどであった。

## 4. どうやって有効だと検証した？
TPUで実験を行なっているがCPUやGPUでは行なっておらず有効であると検証し切れているとは言い難い。

## 5. 議論はあるか？
現状全てのモデルに対応している訳では無い。

## 6. 次に読むべき論文はあるか？
現状なし

### 論文情報・リンク

- [github:Mesh-tensorflow](https://github.com/tensorflow/mesh)
