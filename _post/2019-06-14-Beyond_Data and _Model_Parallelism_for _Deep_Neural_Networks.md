---
layout: post
title:  "Beyond Data and Model Parallelism for Deep Neural Networks"
date:   2019-04-02
categories: parallelization deeplearning
---

## 1. どんなもの？

FlexFlowというDeepLearningのフレームワークを提案。
FlexFlowはハードウェアとニューラルネットワークの情報をもとに、自動で最適な並列化戦略を探索し、最も良い並列化戦略を実行する。

Deep Neural Network(DNN)のOperatorごとに割り当てるデバイスやどのようにテンソルやパラメータを分割するのかを考える。これらの組み合わせが最終的に一つの並列化戦略を形成する。そして形成した並列化戦略をシミュレートし実行時間を予測する。そして新たな並列化戦略を提案し、さらに並列化戦略を改善するするという流れである。並列化戦略の改善にはマルコフ連鎖モンテカルロ法という乱択アルゴリズムが用いられる。

## 2. 先行研究と比べてどこがすごいの？

データ並列、モデル並列といった単純な並列化戦略ではまだまだ高速化できる可能性がある。そのため専門家があらゆる要因を考慮して並列化戦略を設計もしくはチューニングを行っている。それに対してFlexFlowは並列化戦略を自動で探索してくれる。

自動で並列化戦略を探索する手法は強化学習や動的計画法を用いたものが多い。特に強化学習においては実際にハードウェアで実際に計算を実行して時間を計測している。一方FlexFlowは実際に実行することで時間を計測することはできる限りせず、シミュレートする手法を用いているので、並列化戦略の探索時間が今までの手法に比べて非常に短い。

## 3. 技術や手法の"キモ"はどこにある？

並列化戦略の候補は膨大に存在する。そのためそれらの並列化戦略の中からどのようにして最適な並列化戦略を探索するのか、という点が肝になる。
最適な並列化戦略を探索しつつも、探索時間を抑える手法をFlexFlowは用いている。
それはフルシミュレーション、デルタシミュレーション、そしてマルコフ連鎖モンテカルロ法である。

FlexFlowは新たな並列化戦略を提案する際、前の並列化戦略においてどれか一つのOperatorをランダムに選択し、設定をランダムに変更する。そして前の並列化戦略でシミュレートされた実行時間と、新しく生成した並列化戦略でシミュレートした実行時間を比較し、新しく生成した並列化戦略を採択(accept)するかを決定する。なお、新しい並列化戦略が採択されなかった場合はまた、生成元となった戦略からランダムに別の戦略を生成する。

## 4. どうやって有効だと検証した？

既存の並列化戦略と並列化戦略の探索時間も含めて実行時間のベンチマークを比較した。
比較する際には六つのDNNと二つのハードウェアアーキテクチャを用いている。

## 5. 議論はあるか？

* メモリ制約について考えていない
* 四つの仮定が容易に成り立たなくなる
* Operatorの分割方法は人があらかじめ定めている

## 6. 次に読むべき論文はあるか？
FlexFlowではオペレータの分割そのものは人間が考えている。オペレータの分割も自動で行うtofuというフレームワークが提案されている論文が存在する。

### 論文情報・リンク

- [Supporting Very Large Models using Automatic Dataflow Graph Partitioning](https://arxiv.org/abs/1807.08887)
